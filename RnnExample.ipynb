{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP1/fFPihQYU7H+x6EHZElI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amrit2603/Gen-AI/blob/main/RnnExample.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ubEKBZ4c6QdK"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(file_path):\n",
        "  with open(file_path, 'r') as file:\n",
        "    data = file.read()\n",
        "    return data\n",
        "\n",
        "file_path = '/content/01 Harry Potter and the Sorcerers Stone.txt'\n",
        "text  = load_data(file_path).lower()"
      ],
      "metadata": {
        "id": "Atnvd5Bf7st9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text"
      ],
      "metadata": {
        "id": "CUrsklgvBwYC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Tokenization\n",
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "\n",
        "Tokenizer = Tokenizer(oov_token='<OOV>')\n",
        "Tokenizer.fit_on_texts(text)\n",
        "\n",
        "total_words = len(Tokenizer.word_index) + 1"
      ],
      "metadata": {
        "id": "4zEtABPkrg56"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_words"
      ],
      "metadata": {
        "id": "Z2kTES0Etpkz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert text to sequences\n",
        "input_sequences = []\n",
        "tokens = Tokenizer.texts_to_sequences([text])[0] # converts the input text into a list of numbers based on the word index\n",
        "\n",
        "print(tokens)"
      ],
      "metadata": {
        "id": "A6Pe7kC_tuxY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seq_length = 50  # Each input sequence contains 50 words\n",
        "for i in range(seq_length, len(tokens)):\n",
        "    input_sequences.append(tokens[i - seq_length:i + 1])\n"
      ],
      "metadata": {
        "id": "Bt7dUJjm8uFv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(input_sequences[0])"
      ],
      "metadata": {
        "id": "Tj4Ep1Bs89XU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "metadata": {
        "id": "Taz_TJbFjwmG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " input_sequences = np.array(pad_sequences(input_sequences, maxlen=seq_length + 1, padding='pre'))\n",
        " X = input_sequences[:, :-1]\n",
        " y = input_sequences[:, -1]\n",
        "\n",
        "# after this X will have inputs and y will have label for those inputs\n"
      ],
      "metadata": {
        "id": "0Hr5cqOSj2NO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = tf.keras.utils.to_categorical(y, num_classes=total_words)"
      ],
      "metadata": {
        "id": "KderaUTKmHNY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import SimpleRNN , Embedding , Dense"
      ],
      "metadata": {
        "id": "0s6rDy65-E3g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the Simple RNN model\n",
        "model = Sequential([\n",
        "    Embedding(input_dim = total_words, output_dim=64),  # Word embeddings, removed input_length\n",
        "    SimpleRNN(256, return_sequences=False),  # RNN Layer\n",
        "    Dense(256, activation='relu'),  # Fully Connected Layer\n",
        "    Dense(total_words, activation='softmax')  # Output Layer\n",
        "])"
      ],
      "metadata": {
        "id": "-qA4zhA0-agi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fec8ab5b"
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ebcae6bd"
      },
      "source": [
        "model.fit(X , y , epochs=10 , batch_size = 128)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "006e68a1"
      },
      "source": [
        "print(f\"Shape of X: {X.shape}\")\n",
        "print(f\"Shape of y: {y.shape}\")\n",
        "print(f\"First 5 elements of X[0]: {X[0][:5]}\") # Displaying only first 5 tokens of first sequence for brevity\n",
        "print(f\"First 5 elements of X[1]: {X[1][:5]}\")\n",
        "print(f\"First 5 elements of y[0]: {y[0][:5]}\") # Displaying only first 5 elements of one-hot encoded vector\n",
        "print(f\"First 5 elements of y[1]: {y[1][:5]}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to generate text using RNN\n",
        "def generate_text(seed_text, next_words=50):\n",
        "    for _ in range(next_words):\n",
        "        tokenized_input = Tokenizer.texts_to_sequences([seed_text])[0]\n",
        "        tokenized_input = pad_sequences([tokenized_input], maxlen=seq_length, padding='pre')\n",
        "\n",
        "        predicted_probs = model.predict(tokenized_input, verbose=0)\n",
        "        predicted_index = np.argmax(predicted_probs)\n",
        "        predicted_word = Tokenizer.index_word.get(predicted_index, \"\")\n",
        "\n",
        "        seed_text += \" \" + predicted_word\n",
        "    return seed_text\n"
      ],
      "metadata": {
        "id": "sInZ8l0gsu51"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate text using the trained model\n",
        "print(generate_text(\"harry looked at\"))"
      ],
      "metadata": {
        "id": "wwjcZnd9syAl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import SimpleRNN, Embedding, Dense\n",
        "import numpy as np\n",
        "\n",
        "# Load and preprocess text\n",
        "def load_data(file_path):\n",
        "    with open(file_path, 'r', encoding='utf-8') as f:\n",
        "        text = f.read()\n",
        "    return text\n",
        "\n",
        "file_path = '/content/01 Harry Potter and the Sorcerers Stone.txt'\n",
        "text = load_data(file_path).lower()\n",
        "\n",
        "# Tokenization\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.utils import pad_sequences\n",
        "\n",
        "tokenizer = Tokenizer(oov_token='') # Out-Of-Vocabulary token\n",
        "                                        # If a word not seen during training appears later, it will be replaced with\n",
        "                                        # Helps handle unknown words instead of ignoring them\n",
        "tokenizer.fit_on_texts([text]) # analyzes the input text and creates a word index (mapping of words to unique integers)\n",
        "total_words = len(tokenizer.word_index) + 1 #  0 is usually reserved for padding\n",
        "\n",
        "# Convert text to sequences\n",
        "input_sequences = []\n",
        "tokens = tokenizer.texts_to_sequences([text])[0] # converts the input text into a list of numbers based on the word index\n",
        "seq_length = 50  # Each input sequence contains 50 words\n",
        "\n",
        "# First seq_length tokens (input): Used for training the model.\n",
        "# Last token (target): Used as the label the model tries to predict.\n",
        "# so total of (50 + 1) in one input_sequence index\n",
        "\n",
        "for i in range(seq_length, len(tokens)):\n",
        "    input_sequences.append(tokens[i - seq_length:i + 1])\n",
        "\n",
        "# Pad sequences and split inputs/targets\n",
        "# after this X will have inputs and y will have label for those inputs\n",
        "\n",
        "input_sequences = np.array(pad_sequences(input_sequences, maxlen=seq_length + 1, padding='pre'))\n",
        "X, y = input_sequences[:, :-1], input_sequences[:, -1]\n",
        "\n",
        "# One-hot encode the labels , note- there are other ways for\n",
        "# encoding like pre-trained word2vec encoding and so on\n",
        "\n",
        "y = tf.keras.utils.to_categorical(y, num_classes=total_words)\n",
        "\n",
        "# Build the Simple RNN model\n",
        "model = Sequential([\n",
        "    Embedding(input_dim=total_words, output_dim=64, input_length=seq_length),  # Word embeddings\n",
        "    SimpleRNN(256, return_sequences=False),  # RNN Layer\n",
        "    Dense(256, activation='relu'),  # Fully Connected Layer\n",
        "    Dense(total_words, activation='softmax')  # Output Layer\n",
        "])\n",
        "\n",
        "# 256 in RNN - The number of hidden units (size of the hidden state vector)\n",
        "# return_sequences=False  - The RNN will only return the final hidden state after processing the entire sequence\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X, y, epochs=30, batch_size=128)\n",
        "\n",
        "# Function to generate text using RNN\n",
        "def generate_text(seed_text, next_words=50):\n",
        "    for _ in range(next_words):\n",
        "        tokenized_input = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "        tokenized_input = pad_sequences([tokenized_input], maxlen=seq_length, padding='pre')\n",
        "\n",
        "        predicted_probs = model.predict(tokenized_input, verbose=0)\n",
        "        predicted_index = np.argmax(predicted_probs)\n",
        "        predicted_word = tokenizer.index_word.get(predicted_index, \"\")\n",
        "\n",
        "        seed_text += \" \" + predicted_word\n",
        "    return seed_text\n",
        "\n",
        "# Generate text using the trained model\n",
        "print(generate_text(\"harry looked at\"))\n"
      ],
      "metadata": {
        "id": "CHhCbXWyt1DF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The model learns local patterns, not long-term dependencies\n",
        "\n",
        "RNNs struggle with long-range dependencies because they do not retain information well over long sequences.\n",
        "This is why the text seems grammatically okay but lacks deeper context.\n",
        "The model generates phrases based on probabilities\n",
        "\n",
        "It predicts the most likely next word given the past words.\n",
        "It does not understand meaning but follows statistical patterns.\n",
        "It captures writing style but lacks coherence\n",
        "Words appear logically related but do not form a strong narrative. The model does not truly \"understand\" the book, it just mimics word usage.**bold text**"
      ],
      "metadata": {
        "id": "4TvZAhiD6CbX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.utils import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "import numpy as np\n",
        "\n",
        "# Function to load dataset\n",
        "def load_data(file_path):\n",
        "    with open(file_path, 'r', encoding='utf-8') as f:\n",
        "        text = f.read()\n",
        "    return text\n",
        "\n",
        "# Load Harry Potter book text\n",
        "file_path ='/content/01 Harry Potter and the Sorcerers Stone.txt'\n",
        "text = load_data(file_path).lower()\n",
        "\n",
        "# Tokenize the text\n",
        "tokenizer = Tokenizer(oov_token='')\n",
        "tokenizer.fit_on_texts([text])\n",
        "total_words = len(tokenizer.word_index) + 1\n",
        "\n",
        "# Convert text into sequences\n",
        "input_sequences = []\n",
        "tokens = tokenizer.texts_to_sequences([text])[0]\n",
        "seq_length = 50  # Each input sequence will have 50 words\n",
        "\n",
        "for i in range(seq_length, len(tokens)):\n",
        "    input_sequences.append(tokens[i - seq_length:i + 1])\n",
        "\n",
        "# Pad sequences and split into inputs (X) and labels (y)\n",
        "input_sequences = np.array(pad_sequences(input_sequences, maxlen=seq_length + 1, padding='pre'))\n",
        "X, y = input_sequences[:, :-1], input_sequences[:, -1]\n",
        "y = tf.keras.utils.to_categorical(y, num_classes=total_words)  # One-hot encode labels\n",
        "\n",
        "# LSTM Model\n",
        "model = Sequential([\n",
        "    Embedding(input_dim=total_words, output_dim=100, input_length=seq_length),\n",
        "    LSTM(256, return_sequences=True),  # First LSTM layer\n",
        "    LSTM(256),  # Second LSTM layer\n",
        "    Dense(total_words, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X, y, epochs=20, batch_size=128)\n",
        "\n",
        "# Function to Generate Text\n",
        "def generate_text(seed_text, next_words=50, temperature=1.0):\n",
        "    for _ in range(next_words):\n",
        "        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "        token_list = pad_sequences([token_list], maxlen=seq_length, padding='pre')\n",
        "\n",
        "        predicted_probs = model.predict(token_list, verbose=0)[0]\n",
        "        predicted_probs = np.log(predicted_probs) / temperature  # Adjust randomness\n",
        "        predicted_probs = np.exp(predicted_probs) / np.sum(np.exp(predicted_probs))\n",
        "        predicted_index = np.random.choice(range(len(predicted_probs)), p=predicted_probs)\n",
        "\n",
        "        output_word = tokenizer.index_word.get(predicted_index, \"\")\n",
        "        seed_text += \" \" + output_word\n",
        "\n",
        "    return seed_text\n",
        "\n",
        "# Generate text\n",
        "print(generate_text(\"harry looked at\", next_words=50, temperature=0.7))\n"
      ],
      "metadata": {
        "id": "3BItkKm66FVd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.utils import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, GRU, Dense\n",
        "import numpy as np\n",
        "\n",
        "# Function to load dataset\n",
        "def load_data(file_path):\n",
        "    with open(file_path, 'r', encoding='utf-8') as f:\n",
        "        text = f.read()\n",
        "    return text\n",
        "\n",
        "# Load Harry Potter book text\n",
        "file_path = '/content/01 Harry Potter and the Sorcerers Stone.txt'\n",
        "text = load_data(file_path).lower()\n",
        "\n",
        "# Tokenize the text\n",
        "tokenizer = Tokenizer(oov_token='')\n",
        "tokenizer.fit_on_texts([text])\n",
        "total_words = len(tokenizer.word_index) + 1\n",
        "\n",
        "# Convert text into sequences\n",
        "input_sequences = []\n",
        "tokens = tokenizer.texts_to_sequences([text])[0]\n",
        "seq_length = 50  # Each input sequence will have 50 words\n",
        "\n",
        "for i in range(seq_length, len(tokens)):\n",
        "    input_sequences.append(tokens[i - seq_length:i + 1])\n",
        "\n",
        "# Pad sequences and split into inputs (X) and labels (y)\n",
        "input_sequences = np.array(pad_sequences(input_sequences, maxlen=seq_length + 1, padding='pre'))\n",
        "X, y = input_sequences[:, :-1], input_sequences[:, -1]\n",
        "y = tf.keras.utils.to_categorical(y, num_classes=total_words)  # One-hot encode labels\n",
        "\n",
        "# GRU Model\n",
        "model = Sequential([\n",
        "    Embedding(input_dim=total_words, output_dim=100, input_length=seq_length),\n",
        "    GRU(256, return_sequences=True),  # First GRU layer\n",
        "    GRU(256),  # Second GRU layer\n",
        "    Dense(total_words, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X, y, epochs=20, batch_size=128)\n",
        "\n",
        "# Function to Generate Text\n",
        "def generate_text(seed_text, next_words=50, temperature=1.0):\n",
        "    for _ in range(next_words):\n",
        "        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "        token_list = pad_sequences([token_list], maxlen=seq_length, padding='pre')\n",
        "\n",
        "        predicted_probs = model.predict(token_list, verbose=0)[0]\n",
        "        predicted_probs = np.log(predicted_probs) / temperature  # Adjust randomness\n",
        "        predicted_probs = np.exp(predicted_probs) / np.sum(np.exp(predicted_probs))\n",
        "        predicted_index = np.random.choice(range(len(predicted_probs)), p=predicted_probs)\n",
        "\n",
        "        output_word = tokenizer.index_word.get(predicted_index, \"\")\n",
        "        seed_text += \" \" + output_word\n",
        "\n",
        "    return seed_text\n",
        "\n",
        "# Generate text\n",
        "print(generate_text(\"harry looked at\", next_words=50, temperature=0.7))"
      ],
      "metadata": {
        "id": "8Qiia0NX8NAp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}